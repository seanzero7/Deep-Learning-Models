{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**HW2-1**\n"
      ],
      "metadata": {
        "id": "2Xj0gVBrV5Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "metadata": {
        "id": "1ikZeRpD_q93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "5z4Q5xFLAYGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "metadata": {
        "id": "_buc2OwQENZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.Sequential([\n",
        "layers.Dense(512, activation=\"relu\"),\n",
        "layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "u6tm-Fo0BGGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "lFtixsaXBYCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((50000, 32 * 32 * 3))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 32 * 32 * 3))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "GedjZK6cBeJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "#After a handful of trials at 5 and 10 epochs,\n",
        "#I have concluded that more epochs marginally helps improve accuracy."
      ],
      "metadata": {
        "id": "nJmRZqV7Egs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]\n",
        "predictions[1].argmax()\n",
        "test_labels[1]"
      ],
      "metadata": {
        "id": "98rILuNaEl6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ],
      "metadata": {
        "id": "nRnq5fc1EtWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
        "print(f\"train_acc: {train_acc}\")"
      ],
      "metadata": {
        "id": "VRjIZevHGNeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HW2-2**"
      ],
      "metadata": {
        "id": "EiDfEzL3LzP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential([\n",
        "layers.Dense(512, activation=\"relu\"),\n",
        "layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "vV2J__nMMElp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "m3L8Mqc8MO72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "vC4OBa75MQ0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "id": "b2eHNyzOMTp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ],
      "metadata": {
        "id": "I07Yif77MWGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[:10])\n",
        "lst0 = []\n",
        "lst1 = []\n",
        "lst2 = []\n",
        "lst3 = []\n",
        "lst4 = []\n",
        "lst5 = []\n",
        "lst6 = []\n",
        "lst7 = []\n",
        "lst8 = []\n",
        "lst9 = []\n",
        "lst_all = [lst0,lst1,lst2,lst3,lst4,lst5,lst6,lst7,lst8,lst9]"
      ],
      "metadata": {
        "id": "AiwF2NTVSs5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "while i < len(test_labels):\n",
        "    num = test_labels[i]\n",
        "    lst_all[num].append(i)\n",
        "    if all(len(lst) >= 10 for lst in lst_all):\n",
        "        break\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "I13cxNYTg4FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confirming all sublists have at least 10 elements.\n",
        "for lst in lst_all:\n",
        "  print(len(lst))"
      ],
      "metadata": {
        "id": "5PpZx142E5H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plot_idx = 1\n",
        "counter = 0\n",
        "plt.figure(figsize=(10,10))\n",
        "for lst in lst_all:\n",
        "  for i in lst:\n",
        "    counter += 1\n",
        "    if counter > 10:\n",
        "      break\n",
        "    plt.subplot(10,10,plot_idx)\n",
        "    plt.imshow(test_images[i].reshape(28,28), cmap='gray_r')\n",
        "    plt.axis('off')\n",
        "    plot_idx += 1\n",
        "  counter = 0\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "scct-PLWMp8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HW2-3**"
      ],
      "metadata": {
        "id": "wJCkMUP8QNM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_evaluate(model, test_images, test_labels):\n",
        "    predictions = model.predict(test_images)\n",
        "\n",
        "    #Predictions compared with real labels\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    compare = predicted_classes == test_labels\n",
        "    accuracy = np.mean(compare)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "4laWmIsTQOHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the built-in evaluate function in Keras\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc using evaluate: {test_acc}\")\n",
        "\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels)\n",
        "print(f\"train_acc using evaluate: {train_acc}\")"
      ],
      "metadata": {
        "id": "kntlSFmPU2G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using my manual evaluate function\n",
        "test_acc = manual_evaluate(model, test_images, test_labels)\n",
        "print(f\"test_acc using MANUAL evaluate: {test_acc}\")\n",
        "\n",
        "train_acc = manual_evaluate(model, train_images, train_labels)\n",
        "print(f\"train_acc using MANUAL evaluate: {train_acc}\")"
      ],
      "metadata": {
        "id": "GSqln8MHSLWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the above 2 cells, the results from Keras' built-in evaluate() function are the same as my manual evaluate function. This is because they are doing the exact same thing.\n",
        "\n",
        "Albeit, Keras' function does their evaluating in batches, so its faster.\n",
        "\n",
        "All the built-in evaluate function is doing (and what my manual evaluate is doing) is:\n",
        "\n",
        "Predict from given images-> Find the index of the greatest number in the row (The model's best guess) -> Compare the model's guesses to the true labels (predicted_classes == test_labels gives list of True and Falses) -> Take average (When taking mean of True and False, True gets converted to 1 and False into 0)."
      ],
      "metadata": {
        "id": "e9Oo_uWcU0Bm"
      }
    }
  ]
}