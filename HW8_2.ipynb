{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gJs-tG2qn5A1"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)) ## Check the shape\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)) ## Check the shape\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "print(len(train_images))\n",
        "print(len(train_labels))"
      ],
      "metadata": {
        "id": "5Je5wD0LoF6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebf4e2d-f269-4764-cf94-dfe2e436801f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "60000\n",
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_1 = []\n",
        "train_labels_1 = []\n",
        "train_images_2 = []\n",
        "train_labels_2 = []\n",
        "\n",
        "\n",
        "digit_counts = {digit: 0 for digit in range(5, 10)}\n",
        "\n",
        "for i, digit in enumerate(train_labels):\n",
        "    if digit <= 4:\n",
        "        train_images_1.append(train_images[i])\n",
        "        train_labels_1.append(digit)\n",
        "    elif 5 <= digit <= 9 and digit_counts[digit] < 10:\n",
        "        train_images_2.append(train_images[i])\n",
        "        train_labels_2.append(digit)\n",
        "        digit_counts[digit] += 1\n",
        "\n",
        "\n",
        "print(len(train_images_1))\n",
        "print(len(train_labels_1)) #Ensuring same length, and totaling about 30k.\n",
        "\n",
        "print(len(train_images_2))\n",
        "print(len(train_labels_2)) #Ensuring 50 count (10 of each digit > 4)"
      ],
      "metadata": {
        "id": "ks97pGzBoU_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e547a2-9ee2-40bc-f2ab-e8de835e23b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30596\n",
            "30596\n",
            "50\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_1 = []\n",
        "test_labels_1 = []\n",
        "test_images_2 = []\n",
        "test_labels_2 = []\n",
        "\n",
        "for i, digit in enumerate(test_labels):\n",
        "    if digit <= 4:\n",
        "      test_images_1.append(test_images[i])\n",
        "      test_labels_1.append(digit)\n",
        "    else:\n",
        "      test_images_2.append(test_images[i])\n",
        "      test_labels_2.append(digit)\n",
        "\n",
        "print(len(test_images_1))\n",
        "print(len(test_labels_1))\n",
        "\n",
        "print(len(test_images_2))\n",
        "print(len(test_labels_2)) #Ensuring same length, total 5k each."
      ],
      "metadata": {
        "id": "Hlj0GWeV9_Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8864c80-a08d-4a7c-c4c6-77a2de05a27b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5139\n",
            "5139\n",
            "4861\n",
            "4861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffling training set 1 and 2:\n",
        "import numpy as np\n",
        "\n",
        "perm_1 = np.random.permutation(len(train_images_1))\n",
        "train_images_1 = np.array(train_images_1)\n",
        "train_labels_1 = np.array(train_labels_1) #Need to be numpy arrays\n",
        "\n",
        "perm_2 = np.random.permutation(len(train_images_2))\n",
        "train_images_2 = np.array(train_images_2)\n",
        "train_labels_2 = np.array(train_labels_2) #Need to be numpy arrays\n",
        "\n",
        "train_images_1 = train_images_1[perm_1]\n",
        "train_labels_1 = train_labels_1[perm_1]\n",
        "\n",
        "train_images_2 = train_images_2[perm_2]\n",
        "train_labels_2 = train_labels_2[perm_2]\n",
        "\n",
        "\n",
        "\n",
        "#Making test_data a numpy array so they can have shape\n",
        "test_images_1 = np.array(test_images_1)\n",
        "test_images_2 = np.array(test_images_2)\n",
        "test_labels_1 = np.array(test_labels_1)\n",
        "test_labels_2 = np.array(test_labels_2)\n",
        "\n",
        "print(len(train_images_1))\n",
        "print(len(train_images_2))"
      ],
      "metadata": {
        "id": "8jZdU1Nw_Aro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5be9c3-f2fd-46ff-989f-a60935beb1d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30596\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating validation data (20% of train)\n",
        "val_images_1 = train_images_1[:int(.2*len(train_images_1))] #Takes first 20%\n",
        "train_images_1 = train_images_1[int(.2*len(train_images_1)):] #Assigns training images last 80%\n",
        "\n",
        "val_labels_1 = train_labels_1[:int(.2*len(train_labels_1))] #Takes first 20%\n",
        "train_labels_1 = train_labels_1[int(.2*len(train_labels_1)):] #Assigns training labels last 80%\n",
        "\n",
        "val_images_2 = train_images_2[:int(.2*len(train_images_2))] #Repeat for 2\n",
        "train_images_2 = train_images_2[int(.2*len(train_images_2)):]\n",
        "\n",
        "val_labels_2 = train_labels_2[:int(.2*len(train_labels_2))]\n",
        "train_labels_2 = train_labels_2[int(.2*len(train_labels_2)):]"
      ],
      "metadata": {
        "id": "PwhKa4CDCBlu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 1\n",
        "inputs = keras.Input(shape=(28, 28, 1)) ## Different from densenet input\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model_1 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model_1.compile(loss=\"SparseCategoricalCrossentropy\", optimizer=\"rmsprop\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "#Creating ModelCheckpoint callback\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1.keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model_1.fit(train_images_1, train_labels_1,\n",
        "epochs=30,\n",
        "validation_data=(val_images_1,val_labels_1),\n",
        "callbacks=callbacks)"
      ],
      "metadata": {
        "id": "IPbygSxF_BNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5baab985-7a8a-45e0-9f37-8828ba3059c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.2087 - val_accuracy: 0.9912 - val_loss: 0.0278\n",
            "Epoch 2/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0222 - val_accuracy: 0.9948 - val_loss: 0.0173\n",
            "Epoch 3/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0150 - val_accuracy: 0.9953 - val_loss: 0.0157\n",
            "Epoch 4/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0083 - val_accuracy: 0.9956 - val_loss: 0.0151\n",
            "Epoch 5/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9958 - val_loss: 0.0180\n",
            "Epoch 6/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 0.9879 - val_loss: 0.0511\n",
            "Epoch 7/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0057 - val_accuracy: 0.9954 - val_loss: 0.0207\n",
            "Epoch 8/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9958 - val_loss: 0.0220\n",
            "Epoch 9/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 8.4127e-04 - val_accuracy: 0.9954 - val_loss: 0.0289\n",
            "Epoch 10/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 6.9015e-04 - val_accuracy: 0.9958 - val_loss: 0.0296\n",
            "Epoch 11/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.9958 - val_loss: 0.0213\n",
            "Epoch 12/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.4457e-04 - val_accuracy: 0.9969 - val_loss: 0.0242\n",
            "Epoch 13/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6361e-06 - val_accuracy: 0.9956 - val_loss: 0.0286\n",
            "Epoch 14/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1390e-04 - val_accuracy: 0.9964 - val_loss: 0.0226\n",
            "Epoch 15/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1651e-06 - val_accuracy: 0.9967 - val_loss: 0.0232\n",
            "Epoch 16/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5273e-07 - val_accuracy: 0.9967 - val_loss: 0.0233\n",
            "Epoch 17/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4418e-07 - val_accuracy: 0.9967 - val_loss: 0.0235\n",
            "Epoch 18/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0631e-07 - val_accuracy: 0.9966 - val_loss: 0.0233\n",
            "Epoch 19/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0806e-07 - val_accuracy: 0.9966 - val_loss: 0.0235\n",
            "Epoch 20/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8668e-07 - val_accuracy: 0.9966 - val_loss: 0.0235\n",
            "Epoch 21/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2961e-07 - val_accuracy: 0.9967 - val_loss: 0.0235\n",
            "Epoch 22/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9907e-07 - val_accuracy: 0.9967 - val_loss: 0.0236\n",
            "Epoch 23/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8401e-07 - val_accuracy: 0.9967 - val_loss: 0.0236\n",
            "Epoch 24/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5752e-07 - val_accuracy: 0.9967 - val_loss: 0.0237\n",
            "Epoch 25/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1622e-07 - val_accuracy: 0.9967 - val_loss: 0.0237\n",
            "Epoch 26/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5445e-07 - val_accuracy: 0.9967 - val_loss: 0.0238\n",
            "Epoch 27/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6705e-07 - val_accuracy: 0.9967 - val_loss: 0.0239\n",
            "Epoch 28/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9913e-07 - val_accuracy: 0.9967 - val_loss: 0.0240\n",
            "Epoch 29/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2033e-07 - val_accuracy: 0.9967 - val_loss: 0.0240\n",
            "Epoch 30/30\n",
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8508e-07 - val_accuracy: 0.9967 - val_loss: 0.0240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print training/validation results for Model 1 at optimal epochs determined by ModelCheckpoint\n",
        "test_model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "train_loss, train_acc = test_model_1.evaluate(train_images_1,train_labels_1)\n",
        "test_loss, test_acc = test_model_1.evaluate(test_images_1,test_labels_1)\n",
        "print(\"Model 1:\")\n",
        "print(f\"Train accuracy: {train_acc:.3f}\")\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "VIkubg5eENz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e0fdc6-f281-4cd2-d3fe-988904bfe9db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0043\n",
            "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0081\n",
            "Model 1:\n",
            "Train accuracy: 0.999\n",
            "Test accuracy: 0.998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2\n",
        "inputs = keras.Input(shape=(28, 28, 1)) ## Different from densenet input\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model_2 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model_2.compile(loss=\"SparseCategoricalCrossentropy\", optimizer=\"rmsprop\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "#Creating ModelCheckpoint callback\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_2.keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model_2.fit(train_images_2, train_labels_2,\n",
        "epochs=30,\n",
        "validation_data=(val_images_2,val_labels_2),\n",
        "callbacks=callbacks)"
      ],
      "metadata": {
        "id": "oJXqu3SdNjHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001e1190-5068-43ed-89f9-1205dbf27a89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.0542 - loss: 2.3161 - val_accuracy: 0.4000 - val_loss: 1.7672\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.3479 - loss: 1.8206 - val_accuracy: 0.4000 - val_loss: 1.5424\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2938 - loss: 1.5722 - val_accuracy: 0.4000 - val_loss: 1.5355\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5813 - loss: 1.3517 - val_accuracy: 0.4000 - val_loss: 1.3903\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5333 - loss: 1.2274 - val_accuracy: 0.6000 - val_loss: 1.1772\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.9129 - val_accuracy: 0.6000 - val_loss: 1.1626\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6313 - loss: 1.0045 - val_accuracy: 0.7000 - val_loss: 0.9191\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9187 - loss: 0.6889 - val_accuracy: 0.7000 - val_loss: 1.0877\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8646 - loss: 0.5669 - val_accuracy: 0.6000 - val_loss: 1.1079\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8479 - loss: 0.5007 - val_accuracy: 0.7000 - val_loss: 0.7494\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9729 - loss: 0.3602 - val_accuracy: 0.7000 - val_loss: 0.7558\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9729 - loss: 0.2560 - val_accuracy: 0.8000 - val_loss: 0.6854\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9729 - loss: 0.2175 - val_accuracy: 0.7000 - val_loss: 1.2040\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7937 - loss: 0.5191 - val_accuracy: 0.6000 - val_loss: 0.9489\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9458 - loss: 0.2634 - val_accuracy: 0.8000 - val_loss: 0.5902\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9833 - loss: 0.1265 - val_accuracy: 0.6000 - val_loss: 1.0106\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9729 - loss: 0.2142 - val_accuracy: 0.8000 - val_loss: 0.5753\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9729 - loss: 0.1243 - val_accuracy: 0.8000 - val_loss: 0.7299\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0974 - val_accuracy: 0.8000 - val_loss: 0.7018\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0759 - val_accuracy: 0.8000 - val_loss: 0.5445\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0394 - val_accuracy: 0.8000 - val_loss: 0.6777\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0542 - val_accuracy: 0.8000 - val_loss: 0.3925\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0554 - val_accuracy: 0.8000 - val_loss: 0.5088\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.8000 - val_loss: 0.5182\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.8000 - val_loss: 0.4841\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.8000 - val_loss: 0.4908\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.8000 - val_loss: 0.3905\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.8000 - val_loss: 0.3694\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.8000 - val_loss: 0.5423\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.8000 - val_loss: 0.6026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print training/validation results for Model 2 at optimal epochs determined by ModelCheckpoint\n",
        "test_model_2 = keras.models.load_model(\"Model_2.keras\")\n",
        "train_loss, train_acc = test_model_2.evaluate(train_images_2,train_labels_2)\n",
        "test_loss, test_acc = test_model_2.evaluate(test_images_2,test_labels_2)\n",
        "print(\"Model 2:\")\n",
        "print(f\"Train accuracy: {train_acc:.3f}\")\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "O7kg-58LNma-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4293611-6fa5-42bd-c312-fdd8bba2cb9c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826ms/step - accuracy: 1.0000 - loss: 0.0177\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6789 - loss: 1.2701\n",
            "Model 2:\n",
            "Train accuracy: 1.000\n",
            "Test accuracy: 0.731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start of 8-2\n",
        "#Steps: Load model 1 (covnet only), Retrain Dense Layer with training set 2,\n",
        "#report training/test accuracy (with set 2)\n",
        "\n",
        "#Load Model and Freeze Conv Layers:\n",
        "model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "\n",
        "for layer in model_1.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        layer.trainable = False\n",
        "\n",
        "model_1.compile(loss=\"SparseCategoricalCrossentropy\", optimizer=\"rmsprop\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "#Creating ModelCheckpoint callback\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1(NoFineTuning).keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]"
      ],
      "metadata": {
        "id": "vjHXO2fA9012"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Model 1 on Set 2\n",
        "history = model_1.fit(\n",
        "    train_images_2, train_labels_2,\n",
        "    epochs=30,\n",
        "    validation_data=(val_images_2, val_labels_2),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"Model 1 On Set 2 (No fine-tuning):\")\n",
        "model_1 = keras.models.load_model(\"Model_1(NoFineTuning).keras\")\n",
        "#Training accuracy\n",
        "train_loss, train_acc = model_1.evaluate(train_images_2, train_labels_2, verbose=0)\n",
        "print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "\n",
        "#Test accuracy\n",
        "test_loss, test_acc = model_1.evaluate(test_images_2, test_labels_2, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE-q9lU6-qRs",
        "outputId": "17454050-81cb-4335-c0ea-fdb09b096516"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 10.8379 - val_accuracy: 0.0000e+00 - val_loss: 8.7056\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0000e+00 - loss: 7.4325 - val_accuracy: 0.0000e+00 - val_loss: 6.5721\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0542 - loss: 5.0777 - val_accuracy: 0.0000e+00 - val_loss: 4.7186\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0708 - loss: 3.6043 - val_accuracy: 0.0000e+00 - val_loss: 3.5615\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1146 - loss: 2.5959 - val_accuracy: 0.0000e+00 - val_loss: 2.8178\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2771 - loss: 1.9125 - val_accuracy: 0.4000 - val_loss: 2.3215\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4729 - loss: 1.4292 - val_accuracy: 0.4000 - val_loss: 1.9873\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5500 - loss: 1.1300 - val_accuracy: 0.4000 - val_loss: 1.7745\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7563 - loss: 0.9051 - val_accuracy: 0.6000 - val_loss: 1.5783\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8146 - loss: 0.7056 - val_accuracy: 0.6000 - val_loss: 1.4394\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8917 - loss: 0.5707 - val_accuracy: 0.7000 - val_loss: 1.3290\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9187 - loss: 0.4846 - val_accuracy: 0.7000 - val_loss: 1.2329\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9187 - loss: 0.3995 - val_accuracy: 0.7000 - val_loss: 1.1422\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9292 - loss: 0.3333 - val_accuracy: 0.7000 - val_loss: 1.0989\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9458 - loss: 0.2914 - val_accuracy: 0.7000 - val_loss: 1.0133\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.2370 - val_accuracy: 0.7000 - val_loss: 0.9606\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.2218 - val_accuracy: 0.7000 - val_loss: 0.9171\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.1850 - val_accuracy: 0.7000 - val_loss: 0.8837\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.1566 - val_accuracy: 0.7000 - val_loss: 0.8333\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.1416 - val_accuracy: 0.7000 - val_loss: 0.8246\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.1263 - val_accuracy: 0.7000 - val_loss: 0.7900\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.1132 - val_accuracy: 0.7000 - val_loss: 0.7507\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0954 - val_accuracy: 0.7000 - val_loss: 0.6892\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0902 - val_accuracy: 0.7000 - val_loss: 0.6695\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0792 - val_accuracy: 0.7000 - val_loss: 0.6622\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0756 - val_accuracy: 0.7000 - val_loss: 0.6516\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0648 - val_accuracy: 0.7000 - val_loss: 0.6164\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0600 - val_accuracy: 0.7000 - val_loss: 0.5938\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0579 - val_accuracy: 0.7000 - val_loss: 0.5975\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0495 - val_accuracy: 0.7000 - val_loss: 0.5669\n",
            "Model 1 On Set 2 (No fine-tuning):\n",
            "Training accuracy: 1.000\n",
            "Test accuracy: 0.820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pretrain with fine-tuning\n",
        "#Steps: Same as above + unfreeze the last k conv layers,\n",
        "#retrain the whole model with training set 2. Try different k’s (1 - 3) and learning rates (you decide)\n",
        "#k=1,lr=1e-3\n",
        "\n",
        "model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "\n",
        "k = 1  #layers to unfreeze (Testing 1,2,3)\n",
        "conv_layers = []\n",
        "\n",
        "for layer in model_1.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        conv_layers.append(layer)\n",
        "\n",
        "\n",
        "conv_layers = [layer for layer in model_1.layers if isinstance(layer, keras.layers.Conv2D)]\n",
        "#Unfreeze last k layers\n",
        "for layer in conv_layers[-k:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#Testing learning rates 1e-3 and 1e-4\n",
        "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=1e-3), metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1(k=1,lr=1e-3).keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]"
      ],
      "metadata": {
        "id": "Uu5VxLghAJNQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1.fit(\n",
        "    train_images_2, train_labels_2,\n",
        "    epochs=30,\n",
        "    validation_data=(val_images_2, val_labels_2),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"Model 1 On Set 2, Fine-tuning, k=1,LR=1e-3):\")\n",
        "model_1 = keras.models.load_model(\"Model_1(k=1,lr=1e-3).keras\")\n",
        "\n",
        "#Training accuracy\n",
        "train_loss, train_acc = model_1.evaluate(train_images_2, train_labels_2, verbose=0)\n",
        "print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "\n",
        "#Test accuracy\n",
        "test_loss, test_acc = model_1.evaluate(test_images_2, test_labels_2, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVAW2FI4Aljg",
        "outputId": "1f0b776b-dade-4c78-ce52-6e98b7dfdbbf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 10.2240 - val_accuracy: 0.0000e+00 - val_loss: 3.8732\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.0167 - loss: 3.2313 - val_accuracy: 0.3000 - val_loss: 2.1672\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4292 - loss: 1.5886 - val_accuracy: 0.4000 - val_loss: 1.4826\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8313 - loss: 0.8919 - val_accuracy: 0.5000 - val_loss: 1.1334\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9187 - loss: 0.5742 - val_accuracy: 0.6000 - val_loss: 0.8903\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9563 - loss: 0.3844 - val_accuracy: 0.7000 - val_loss: 0.8261\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.2648 - val_accuracy: 0.7000 - val_loss: 0.7400\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.1854 - val_accuracy: 0.7000 - val_loss: 0.6450\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.1360 - val_accuracy: 0.7000 - val_loss: 0.6129\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.1011 - val_accuracy: 0.7000 - val_loss: 0.5619\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0836 - val_accuracy: 0.8000 - val_loss: 0.5580\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0628 - val_accuracy: 0.8000 - val_loss: 0.5462\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0519 - val_accuracy: 0.8000 - val_loss: 0.4994\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0438 - val_accuracy: 0.8000 - val_loss: 0.4996\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0346 - val_accuracy: 0.8000 - val_loss: 0.5260\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.8000 - val_loss: 0.5047\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 0.8000 - val_loss: 0.5073\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.8000 - val_loss: 0.4523\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.8000 - val_loss: 0.5059\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.8000 - val_loss: 0.4779\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.8000 - val_loss: 0.5387\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.8000 - val_loss: 0.4904\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8000 - val_loss: 0.4697\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8000 - val_loss: 0.4397\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8000 - val_loss: 0.4550\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8000 - val_loss: 0.4369\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8000 - val_loss: 0.4211\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8000 - val_loss: 0.4302\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8000 - val_loss: 0.4452\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8000 - val_loss: 0.4478\n",
            "Model 1 On Set 2, Fine-tuning, k=1,LR=1e-3):\n",
            "Training accuracy: 1.000\n",
            "Test accuracy: 0.793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k=2,lr=1e-3\n",
        "model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "\n",
        "k = 2  #layers to unfreeze (Testing 1,2,3)\n",
        "conv_layers = []\n",
        "\n",
        "for layer in model_1.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        conv_layers.append(layer)\n",
        "\n",
        "\n",
        "conv_layers = [layer for layer in model_1.layers if isinstance(layer, keras.layers.Conv2D)]\n",
        "#Unfreeze last k layers\n",
        "for layer in conv_layers[-k:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#Testing learning rates 1e-3 and 1e-4\n",
        "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=1e-3), metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1(k=2,lr=1e-3).keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]\n",
        "history = model_1.fit(\n",
        "    train_images_2, train_labels_2,\n",
        "    epochs=30,\n",
        "    validation_data=(val_images_2, val_labels_2),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "model_1 = keras.models.load_model(\"Model_1(k=2,lr=1e-3).keras\")\n",
        "print(\"Model 1 On Set 2, Fine-tuning, k=2,LR=1e-3):\")\n",
        "#Training accuracy\n",
        "train_loss, train_acc = model_1.evaluate(train_images_2, train_labels_2, verbose=0)\n",
        "print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "\n",
        "#Test accuracy\n",
        "test_loss, test_acc = model_1.evaluate(test_images_2, test_labels_2, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EccUjXNpDTss",
        "outputId": "8bca1df8-4faa-4e71-c7ee-655e4949056b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 10.1751 - val_accuracy: 0.0000e+00 - val_loss: 3.9379\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.0542 - loss: 3.0641 - val_accuracy: 0.1000 - val_loss: 2.2630\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5396 - loss: 1.5583 - val_accuracy: 0.3000 - val_loss: 1.6248\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6958 - loss: 0.9464 - val_accuracy: 0.3000 - val_loss: 1.2827\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8646 - loss: 0.6119 - val_accuracy: 0.6000 - val_loss: 0.9493\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9729 - loss: 0.3928 - val_accuracy: 0.7000 - val_loss: 0.8242\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9833 - loss: 0.2684 - val_accuracy: 0.7000 - val_loss: 0.7404\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.2106 - val_accuracy: 0.7000 - val_loss: 0.6789\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1461 - val_accuracy: 0.7000 - val_loss: 0.5996\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1044 - val_accuracy: 0.8000 - val_loss: 0.6020\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0786 - val_accuracy: 0.7000 - val_loss: 0.5593\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.8000 - val_loss: 0.5503\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0516 - val_accuracy: 0.8000 - val_loss: 0.5370\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0407 - val_accuracy: 0.8000 - val_loss: 0.4848\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0323 - val_accuracy: 0.8000 - val_loss: 0.4990\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 0.8000 - val_loss: 0.4389\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.8000 - val_loss: 0.4627\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.8000 - val_loss: 0.4535\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.8000 - val_loss: 0.4229\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.8000 - val_loss: 0.4388\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8000 - val_loss: 0.4648\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.8000 - val_loss: 0.4359\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.8000 - val_loss: 0.4363\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8000 - val_loss: 0.4281\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8000 - val_loss: 0.4066\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.8000 - val_loss: 0.3847\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8000 - val_loss: 0.4029\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.8000 - val_loss: 0.4231\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8000 - val_loss: 0.3879\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8000 - val_loss: 0.3787\n",
            "Model 1 On Set 2, Fine-tuning, k=2,LR=1e-3):\n",
            "Training accuracy: 1.000\n",
            "Test accuracy: 0.786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k=3,lr=1e-3\n",
        "model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "\n",
        "k = 3  #layers to unfreeze (Testing 1,2,3)\n",
        "conv_layers = []\n",
        "\n",
        "for layer in model_1.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        conv_layers.append(layer)\n",
        "\n",
        "\n",
        "conv_layers = [layer for layer in model_1.layers if isinstance(layer, keras.layers.Conv2D)]\n",
        "#Unfreeze last k layers\n",
        "for layer in conv_layers[-k:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#Testing learning rates 1e-3 and 1e-4\n",
        "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=1e-3), metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1(k=3,lr=1e-3).keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]\n",
        "history = model_1.fit(\n",
        "    train_images_2, train_labels_2,\n",
        "    epochs=30,\n",
        "    validation_data=(val_images_2, val_labels_2),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "model_1 = keras.models.load_model(\"Model_1(k=3,lr=1e-3).keras\")\n",
        "\n",
        "print(\"Model 1 On Set 2, Fine-tuning, k=3,LR=1e-3):\")\n",
        "#Training accuracy\n",
        "train_loss, train_acc = model_1.evaluate(train_images_2, train_labels_2, verbose=0)\n",
        "print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "\n",
        "#Test accuracy\n",
        "test_loss, test_acc = model_1.evaluate(test_images_2, test_labels_2, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCDx9uw0Dq0A",
        "outputId": "d4388590-90fc-4dad-d75a-fbe86dd44a71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 10.4483 - val_accuracy: 0.0000e+00 - val_loss: 4.1229\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.0500 - loss: 3.1660 - val_accuracy: 0.2000 - val_loss: 2.1564\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4896 - loss: 1.3999 - val_accuracy: 0.4000 - val_loss: 1.4206\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7937 - loss: 0.8437 - val_accuracy: 0.4000 - val_loss: 1.1283\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.5470 - val_accuracy: 0.7000 - val_loss: 0.9248\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.3511 - val_accuracy: 0.6000 - val_loss: 0.7996\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9833 - loss: 0.2482 - val_accuracy: 0.7000 - val_loss: 0.6825\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1725 - val_accuracy: 0.7000 - val_loss: 0.6952\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1348 - val_accuracy: 0.7000 - val_loss: 0.6049\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0922 - val_accuracy: 0.8000 - val_loss: 0.5957\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0738 - val_accuracy: 0.8000 - val_loss: 0.5670\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0556 - val_accuracy: 0.8000 - val_loss: 0.5946\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0475 - val_accuracy: 0.8000 - val_loss: 0.5441\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 0.8000 - val_loss: 0.5292\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 0.8000 - val_loss: 0.4925\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.8000 - val_loss: 0.4886\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.8000 - val_loss: 0.5073\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.8000 - val_loss: 0.4828\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.8000 - val_loss: 0.4760\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.8000 - val_loss: 0.4599\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.8000 - val_loss: 0.4787\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.8000 - val_loss: 0.4916\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8000 - val_loss: 0.4655\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8000 - val_loss: 0.4545\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8000 - val_loss: 0.4433\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8000 - val_loss: 0.4434\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.8000 - val_loss: 0.4635\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8000 - val_loss: 0.4477\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8000 - val_loss: 0.4409\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8000 - val_loss: 0.4444\n",
            "Model 1 On Set 2, Fine-tuning, k=3,LR=1e-3):\n",
            "Training accuracy: 1.000\n",
            "Test accuracy: 0.795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#=1,lr=1e-4\n",
        "model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "\n",
        "k = 1  #layers to unfreeze (Testing 1,2,3)\n",
        "conv_layers = []\n",
        "\n",
        "for layer in model_1.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        conv_layers.append(layer)\n",
        "\n",
        "\n",
        "conv_layers = [layer for layer in model_1.layers if isinstance(layer, keras.layers.Conv2D)]\n",
        "#Unfreeze last k layers\n",
        "for layer in conv_layers[-k:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#Testing learning rates 1e-3 and 1e-4\n",
        "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=1e-4), metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1(k=1,lr=1e-4).keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]\n",
        "history = model_1.fit(\n",
        "    train_images_2, train_labels_2,\n",
        "    epochs=30,\n",
        "    validation_data=(val_images_2, val_labels_2),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "model_1 = keras.models.load_model(\"Model_1(k=1,lr=1e-4).keras\")\n",
        "\n",
        "print(\"Model 1 On Set 2, Fine-tuning, k=1,LR=1e-4):\")\n",
        "#Training accuracy\n",
        "train_loss, train_acc = model_1.evaluate(train_images_2, train_labels_2, verbose=0)\n",
        "print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "\n",
        "#Test accuracy\n",
        "test_loss, test_acc = model_1.evaluate(test_images_2, test_labels_2, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQgPq4LSDvl2",
        "outputId": "8e7c73ec-11f0-4464-abb8-80965c09f852"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 11.0153 - val_accuracy: 0.0000e+00 - val_loss: 11.3609\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 9.8875 - val_accuracy: 0.0000e+00 - val_loss: 10.5160\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0000e+00 - loss: 9.2933 - val_accuracy: 0.0000e+00 - val_loss: 9.9874\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 8.7484 - val_accuracy: 0.0000e+00 - val_loss: 9.5286\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: 8.2068 - val_accuracy: 0.0000e+00 - val_loss: 9.0849\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.0000e+00 - loss: 7.6023 - val_accuracy: 0.0000e+00 - val_loss: 8.6349\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: 7.2852 - val_accuracy: 0.0000e+00 - val_loss: 8.2877\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 6.9787 - val_accuracy: 0.0000e+00 - val_loss: 7.9461\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0000e+00 - loss: 6.7061 - val_accuracy: 0.0000e+00 - val_loss: 7.6306\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 6.3853 - val_accuracy: 0.0000e+00 - val_loss: 7.3048\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0000e+00 - loss: 6.0930 - val_accuracy: 0.0000e+00 - val_loss: 7.0356\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0000e+00 - loss: 5.6697 - val_accuracy: 0.0000e+00 - val_loss: 6.7289\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0000e+00 - loss: 5.5484 - val_accuracy: 0.0000e+00 - val_loss: 6.4982\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 5.2418 - val_accuracy: 0.0000e+00 - val_loss: 6.2196\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0000e+00 - loss: 5.0078 - val_accuracy: 0.0000e+00 - val_loss: 5.9477\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0000e+00 - loss: 4.8004 - val_accuracy: 0.0000e+00 - val_loss: 5.6948\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 4.5705 - val_accuracy: 0.0000e+00 - val_loss: 5.4839\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0000e+00 - loss: 4.3735 - val_accuracy: 0.0000e+00 - val_loss: 5.2703\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0000e+00 - loss: 4.1958 - val_accuracy: 0.0000e+00 - val_loss: 5.0762\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0000e+00 - loss: 3.9985 - val_accuracy: 0.0000e+00 - val_loss: 4.8565\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0000e+00 - loss: 3.7720 - val_accuracy: 0.0000e+00 - val_loss: 4.6316\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0000e+00 - loss: 3.5358 - val_accuracy: 0.0000e+00 - val_loss: 4.4301\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 3.4372 - val_accuracy: 0.0000e+00 - val_loss: 4.2693\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0271 - loss: 3.2522 - val_accuracy: 0.0000e+00 - val_loss: 4.0816\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0708 - loss: 3.1351 - val_accuracy: 0.0000e+00 - val_loss: 3.9375\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.0813 - loss: 2.8995 - val_accuracy: 0.0000e+00 - val_loss: 3.7498\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0979 - loss: 2.7841 - val_accuracy: 0.0000e+00 - val_loss: 3.5902\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1083 - loss: 2.6119 - val_accuracy: 0.0000e+00 - val_loss: 3.4282\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1146 - loss: 2.5315 - val_accuracy: 0.0000e+00 - val_loss: 3.2976\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1521 - loss: 2.3999 - val_accuracy: 0.0000e+00 - val_loss: 3.1706\n",
            "Model 1 On Set 2, Fine-tuning, k=1,LR=1e-4):\n",
            "Training accuracy: 0.150\n",
            "Test accuracy: 0.059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k=2,lr=1e-4\n",
        "model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "\n",
        "k = 2  #layers to unfreeze (Testing 1,2,3)\n",
        "conv_layers = []\n",
        "\n",
        "for layer in model_1.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        conv_layers.append(layer)\n",
        "\n",
        "\n",
        "conv_layers = [layer for layer in model_1.layers if isinstance(layer, keras.layers.Conv2D)]\n",
        "#Unfreeze last k layers\n",
        "for layer in conv_layers[-k:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#Testing learning rates 1e-3 and 1e-4\n",
        "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=1e-4), metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1(k=2,lr=1e-4).keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]\n",
        "history = model_1.fit(\n",
        "    train_images_2, train_labels_2,\n",
        "    epochs=30,\n",
        "    validation_data=(val_images_2, val_labels_2),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "model_1 = keras.models.load_model(\"Model_1(k=2,lr=1e-4).keras\")\n",
        "\n",
        "print(\"Model 1 On Set 2, Fine-tuning, k=2,LR=1e-4):\")\n",
        "#Training accuracy\n",
        "train_loss, train_acc = model_1.evaluate(train_images_2, train_labels_2, verbose=0)\n",
        "print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "\n",
        "#Test accuracy\n",
        "test_loss, test_acc = model_1.evaluate(test_images_2, test_labels_2, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfE6DOc3D1xG",
        "outputId": "eb5679c6-8f85-4374-e464-10c87f375d88"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 10.9257 - val_accuracy: 0.0000e+00 - val_loss: 11.2513\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.0000e+00 - loss: 9.8132 - val_accuracy: 0.0000e+00 - val_loss: 10.4945\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.0000e+00 - loss: 9.0340 - val_accuracy: 0.0000e+00 - val_loss: 9.8627\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0000e+00 - loss: 8.5047 - val_accuracy: 0.0000e+00 - val_loss: 9.3864\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.0000e+00 - loss: 8.0405 - val_accuracy: 0.0000e+00 - val_loss: 8.9411\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.0000e+00 - loss: 7.6797 - val_accuracy: 0.0000e+00 - val_loss: 8.5563\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0000e+00 - loss: 7.3635 - val_accuracy: 0.0000e+00 - val_loss: 8.2298\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0000e+00 - loss: 6.8381 - val_accuracy: 0.0000e+00 - val_loss: 7.8656\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0000e+00 - loss: 6.6271 - val_accuracy: 0.0000e+00 - val_loss: 7.5365\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0000e+00 - loss: 6.4164 - val_accuracy: 0.0000e+00 - val_loss: 7.2902\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0000e+00 - loss: 6.0645 - val_accuracy: 0.0000e+00 - val_loss: 6.9888\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0000e+00 - loss: 5.7052 - val_accuracy: 0.0000e+00 - val_loss: 6.6998\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0000e+00 - loss: 5.4223 - val_accuracy: 0.0000e+00 - val_loss: 6.3967\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.0000e+00 - loss: 5.2383 - val_accuracy: 0.0000e+00 - val_loss: 6.1505\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0000e+00 - loss: 4.9361 - val_accuracy: 0.0000e+00 - val_loss: 5.8803\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 4.7472 - val_accuracy: 0.0000e+00 - val_loss: 5.6484\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0000e+00 - loss: 4.5171 - val_accuracy: 0.0000e+00 - val_loss: 5.4157\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 4.3699 - val_accuracy: 0.0000e+00 - val_loss: 5.2244\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 4.1746 - val_accuracy: 0.0000e+00 - val_loss: 5.0155\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 3.9305 - val_accuracy: 0.0000e+00 - val_loss: 4.8063\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: 3.6739 - val_accuracy: 0.0000e+00 - val_loss: 4.5782\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.0000e+00 - loss: 3.5718 - val_accuracy: 0.0000e+00 - val_loss: 4.3787\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.0000e+00 - loss: 3.3392 - val_accuracy: 0.0000e+00 - val_loss: 4.1922\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0813 - loss: 3.2325 - val_accuracy: 0.0000e+00 - val_loss: 4.0255\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0813 - loss: 3.0523 - val_accuracy: 0.0000e+00 - val_loss: 3.8368\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0979 - loss: 2.8464 - val_accuracy: 0.0000e+00 - val_loss: 3.6477\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0979 - loss: 2.7284 - val_accuracy: 0.0000e+00 - val_loss: 3.4980\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1250 - loss: 2.5982 - val_accuracy: 0.0000e+00 - val_loss: 3.3531\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1146 - loss: 2.4456 - val_accuracy: 0.0000e+00 - val_loss: 3.2064\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1521 - loss: 2.3312 - val_accuracy: 0.0000e+00 - val_loss: 3.0890\n",
            "Model 1 On Set 2, Fine-tuning, k=2,LR=1e-4):\n",
            "Training accuracy: 0.150\n",
            "Test accuracy: 0.063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#k=3,lr=1e-4\n",
        "model_1 = keras.models.load_model(\"Model_1.keras\")\n",
        "\n",
        "k = 3  #layers to unfreeze (Testing 1,2,3)\n",
        "conv_layers = []\n",
        "\n",
        "for layer in model_1.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        conv_layers.append(layer)\n",
        "\n",
        "\n",
        "conv_layers = [layer for layer in model_1.layers if isinstance(layer, keras.layers.Conv2D)]\n",
        "#Unfreeze last k layers\n",
        "for layer in conv_layers[-k:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#Testing learning rates 1e-3 and 1e-4\n",
        "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=1e-4), metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=\"Model_1(k=3,lr=1e-4).keras\",\n",
        "save_best_only=True,\n",
        "monitor=\"val_loss\")\n",
        "]\n",
        "history = model_1.fit(\n",
        "    train_images_2, train_labels_2,\n",
        "    epochs=30,\n",
        "    validation_data=(val_images_2, val_labels_2),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "model_1 = keras.models.load_model(\"Model_1(k=3,lr=1e-4).keras\")\n",
        "\n",
        "print(\"Model 1 On Set 2, Fine-tuning, k=3,LR=1e-4):\")\n",
        "#Training accuracy\n",
        "train_loss, train_acc = model_1.evaluate(train_images_2, train_labels_2, verbose=0)\n",
        "print(f\"Training accuracy: {train_acc:.3f}\")\n",
        "\n",
        "#Test accuracy\n",
        "test_loss, test_acc = model_1.evaluate(test_images_2, test_labels_2, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoxJlBIjEFP4",
        "outputId": "5e082ac0-5a99-447d-ee26-7f3c65b53763"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 11.0401 - val_accuracy: 0.0000e+00 - val_loss: 11.2914\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0000e+00 - loss: 9.8932 - val_accuracy: 0.0000e+00 - val_loss: 10.5455\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0000e+00 - loss: 9.1843 - val_accuracy: 0.0000e+00 - val_loss: 9.9801\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 8.6572 - val_accuracy: 0.0000e+00 - val_loss: 9.4557\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: 8.2089 - val_accuracy: 0.0000e+00 - val_loss: 9.0249\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 7.5844 - val_accuracy: 0.0000e+00 - val_loss: 8.6149\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0000e+00 - loss: 7.2063 - val_accuracy: 0.0000e+00 - val_loss: 8.2029\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 6.9588 - val_accuracy: 0.0000e+00 - val_loss: 7.8588\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 6.5349 - val_accuracy: 0.0000e+00 - val_loss: 7.4991\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.0000e+00 - loss: 6.2451 - val_accuracy: 0.0000e+00 - val_loss: 7.1814\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0000e+00 - loss: 5.9713 - val_accuracy: 0.0000e+00 - val_loss: 6.8966\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0000e+00 - loss: 5.6885 - val_accuracy: 0.0000e+00 - val_loss: 6.6320\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 5.3860 - val_accuracy: 0.0000e+00 - val_loss: 6.3925\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0000e+00 - loss: 5.2104 - val_accuracy: 0.0000e+00 - val_loss: 6.1655\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 4.9957 - val_accuracy: 0.0000e+00 - val_loss: 5.9041\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 4.6092 - val_accuracy: 0.0000e+00 - val_loss: 5.6523\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 4.5064 - val_accuracy: 0.0000e+00 - val_loss: 5.4186\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 4.1784 - val_accuracy: 0.0000e+00 - val_loss: 5.1887\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: 4.0662 - val_accuracy: 0.0000e+00 - val_loss: 4.9776\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 3.8842 - val_accuracy: 0.0000e+00 - val_loss: 4.7757\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.0000e+00 - loss: 3.6896 - val_accuracy: 0.0000e+00 - val_loss: 4.5888\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0000e+00 - loss: 3.4857 - val_accuracy: 0.0000e+00 - val_loss: 4.4016\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.0437 - loss: 3.3215 - val_accuracy: 0.0000e+00 - val_loss: 4.2304\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0708 - loss: 3.1931 - val_accuracy: 0.0000e+00 - val_loss: 4.0755\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0979 - loss: 3.0304 - val_accuracy: 0.0000e+00 - val_loss: 3.8802\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0875 - loss: 2.8779 - val_accuracy: 0.0000e+00 - val_loss: 3.7394\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0979 - loss: 2.7457 - val_accuracy: 0.0000e+00 - val_loss: 3.5964\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1354 - loss: 2.5443 - val_accuracy: 0.0000e+00 - val_loss: 3.4345\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1250 - loss: 2.4399 - val_accuracy: 0.0000e+00 - val_loss: 3.2837\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1792 - loss: 2.2972 - val_accuracy: 0.0000e+00 - val_loss: 3.1424\n",
            "Model 1 On Set 2, Fine-tuning, k=3,LR=1e-4):\n",
            "Training accuracy: 0.200\n",
            "Test accuracy: 0.078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''The Final Results are (Yours may be slightly different):\n",
        "No Fine Tuning -\n",
        "Training accuracy: 1.000\n",
        "Test accuracy: 0.820\n",
        "\n",
        "Model 1 On Set 2, Fine-tuning, k=1,LR=1e-3):\n",
        "Training accuracy: 1.000\n",
        "Test accuracy: 0.793\n",
        "\n",
        "Model 1 On Set 2, Fine-tuning, k=2,LR=1e-3):\n",
        "Training accuracy: 1.000\n",
        "Test accuracy: 0.786\n",
        "\n",
        "Model 1 On Set 2, Fine-tuning, k=3,LR=1e-3):\n",
        "Training accuracy: 1.000\n",
        "Test accuracy: 0.795\n",
        "\n",
        "Model 1 On Set 2, Fine-tuning, k=1,LR=1e-4):\n",
        "Training accuracy: 0.150\n",
        "Test accuracy: 0.059\n",
        "\n",
        "Model 1 On Set 2, Fine-tuning, k=2,LR=1e-4):\n",
        "Training accuracy: 0.150\n",
        "Test accuracy: 0.063\n",
        "\n",
        "Model 1 On Set 2, Fine-tuning, k=3,LR=1e-4):\n",
        "Training accuracy: 0.200\n",
        "Test accuracy: 0.078 '''\n",
        "#As we can see, The no-fine tuning model did the best.\n",
        "#Followed closely behind is the fine-tuned models with lr=1e-3.\n",
        "#Far behind in last place is the fine-tuned models with lr=1e-4.\n",
        "\n",
        "#Intuitively, I thought the fine-tuned models would do better, and I was surprised\n",
        "#to see that the original model did the best.\n",
        "#The weights developed by the first model on the first training set must have been very\n",
        "#similiar to the weights developed on a model training solely on the 2nd set. This\n",
        "#could be due to the line like nature of the digits, or how the white lines contrast\n",
        "#against the black or a combination of the two."
      ],
      "metadata": {
        "id": "xoeINO3gKhQl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}